# Motivação

Suponha que tenhamos um conjunto de dados de treino \\( x ^{(1)}, x ^{(2)}, \dots , x ^{(m)} \\). E dado um novo exemplo
de treino \\( x _{test} \\) queremos saber se esse dado pode ser considerado anormal ou anômalo.

Para isso, nós definimos uma espécie de "modelo" \\( p(x) \\) que nos diz a probabilidade do exemplo não
ser anômalo. Usamos, também uma _flag_ \\( \epsilon \\) (epsilon) que serve como uma divisão no nosso conjunto
de dados que diferencia os dados anômalos e não anômalos.

Uma aplicação comum de detecção de anomalias é a detecção de fraudes:

- \\( x ^{(i)} \\) = dados das atividades do usuário \\( i \\)

- Modelo \\( p(x) \\) dos dados

- Identifica usuários não usuais checando se \\( p(x) \< \epsilon \\)

Assim, caso o exemplo \\( x ^{(i)} \\) seja considerado anômalo, o valor de \\( p(x) \< \epsilon \\), caso contrário
\\( p(x \geq \epsilon) \\).

Caso o detector de anomalias esteja detectando muitos exemplos anômalos, devemos diminuir o valor
da _flag_ \\( \epsilon \\).
