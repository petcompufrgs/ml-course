# Algoritmo Gradiente Descendente

---

**Algorithm 1** Algoritmo Gradiente Descendente

---

1: **procedure**

2: &emsp; **repeat**

3: &emsp;&emsp;
\\( \theta _j := \theta _j - \alpha \frac{\partial}{\partial \theta _j} J(\theta _0, \theta _1) \\)
&emsp; \\( \rhd \\) (para \\( j=0 \dots m \\))

4: &emsp; **until** \\( convergir \\)

5: **end procedure**

---

Enquanto o método de gradiente descendente não convergir para o mínimo da função, a cada iteração,
atualizamos simultaneamente os valores de \\( \theta _1, \theta _2, \dots , \theta _n \\) fazendo com que
esses valores se aproximem cada vez mais ao mínimo da função.

Podemos perceber que o valor de \\( \alpha \\) tem um certo impacto na atualização dos valores de \\( \theta \\).
Valores de \\( \alpha \\) pequenos, a convergência do método gradiente descendente é mais lenta. E para valores de
\\( \alpha \\) muito grandes, a convergência do método gradiente pode ultrapassar o mínimo, o que pode
impossibilitar a convergência da função.
