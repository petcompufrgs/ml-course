# Gradiente Descendente para Regressão Linear

Podemos utilizar o método de gradiente descendente para minimizar a função _Mean squared error_
utilizada no algoritmo de regressão linear, substituído a função \\( J(\theta _0, \theta _1) \\) por nossa função hipótese.
Dessa forma, o algoritmo de gradiente descendente para a minimização da função \\( J \\) terá a seguinte estrutura:

---

**Algorithm 2** Algoritmo Gradiente Descendente Para Minimização Da Função J

---

1: **procedure**

2: &emsp; **repeat**

3: &emsp;&emsp;
\\( \theta _0 := \theta _0 - \alpha \frac{1}{m} \sum _{i=1} ^m (h _{\theta}(x ^{(i)}) - y ^{(i)}) \\)

4: &emsp;&emsp;
\\( \theta _1 := \theta _1 - \alpha \frac{1}{m} \sum _{i=1} ^m (h _{\theta}(x ^{(i)}) - y ^{(i)}) \cdot x ^{(i)} \\)

5: &emsp; **until** \\( convergir \\)

6: **end procedure**

---

Onde \\( m \\) é o tamanho do conjunto de treino; \\( \theta _0 \\) uma constante que será atualizada simultaneamente
com \\( \theta _1 \\); e \\( x ^{(i)}, y ^{(i)} \\) são valores dados no conjunto de treino.

Esse algoritmo é aplicado para todos os valores dados no conjunto de treino, chamamos isso de _batch gradient descent_.
Dessa forma, quando aplicamos o algoritmo, a função \\( J \\) possui apenas um mínimo
global (sem outros mínimos locais). Portanto, a função de gradiente descendente sempre converge
para regressões lineares, pois \\( J \\) é uma função quadrática convexa.

Nas próximas seções, veremos alguns métodos de otimização desse algoritmo utilizando álgebra linear.
