# Algoritmo

Agora, podemos verificar como funciona esse algoritmo na prática.

---

**Algorithm 7** _Backpropagation Algorithm_

---

1: **procedure** \\( BACKPROPAGATION \\) (Training set
  \\( [(x ^{(1)},y ^{(1)}), \dots , (x ^{(m)}, y^{(m)})] \\))

2: &emsp; Inicializar \\( \Delta _{ij} ^{(l)} = 0 \\)

3: &emsp; **for** \\( i=1 \\) **to** \\( m \\) **do**

4: &emsp;&emsp; Inicializar \\( a ^{(1)} = x ^{(i)} \\)

5: &emsp;&emsp; Realizar *forward propagation* para computar \\( a ^{(l)} \\)
&emsp; \\( \rhd \\ para \\ l=2,3, \dots , L \\)

6: &emsp;&emsp; Usando \\( y ^{(i)} \\), computar \\( \delta ^{(L)} = a ^{(L)} - y ^{(i)} \\)

7: &emsp;&emsp; Computar \\( \delta ^{(L-1)}, \delta ^{(L-2)}, \dots , \delta ^{(2)} \\)

8: &emsp;&emsp;
\\( \Delta _{ij} ^{(l)} := \Delta _{ij} ^{(l)} + a _j ^{(l)} \delta _i ^{(l+1)} \\)

9: &emsp; **end for**

10:&emsp; **if** \\( j \neq 0 \\) **then**

11:&emsp;&emsp;
\\( D _{(ij)} ^{(l)} := \frac{1}{m} \Delta _{ij} ^{(l)} + \lambda \Theta _{ij} ^{(l)} \\)
&emsp; \\( \rhd \frac{\partial}{\partial \Theta _{ij} ^{(l)}} J(\Theta) = D _{(ij)} ^{(l)} \\)

12:&emsp; **else**

13:&emsp;&emsp; \\( D _{(ij)} ^{(l)} := \frac{1}{m} \Delta _{ij} ^{(l)} \\)

14:&emsp; **end if**

15:**end procedure**

---

Realizando uma análise do algoritmo, temos que na linha 2 inicializamos \\( \Delta _{ij} ^{(l)} \\)
com zeros, gerando uma matriz de zeros. No _loop for_ inicializamos as variáveis \\( a ^{(1)} \\) com os
valores da _input layer_ e, depois realizamos _forward propagation_ para computar os valores de \\( a ^{(l)} \\).
Para cada valor de \\( a ^{(l)} \\) definido, computamos os valores de \\( \delta ^{(l)} \\) através
de _backpropagation_, na linha 6 e 7 sabendo que

---

\\[
  \large{} \delta ^{(l)} = ((\Theta ^{(l)}) ^T \delta (l-1)) * a ^{(l)} * (1-a ^{(l)})
\\]

---

Computamos os valores de \\( \delta ^{(l)} \\) começando na camada \\( L \\) da rede neural até a camada 2. Utilizamos
os valores de delta para armazenar o erro presente em cada um dos vetores dos nodos de ativação
\\( a ^{(l)} \\).

Por fim, na linha 8, calculamos os valores de \\( \Theta _{ij} ^{(l)} \\) e determinamos o valor da derivada de
\\( J(\Theta) \\), armazenando em \\( D _{(ij)} ^{(l)} \\) nas linhas 11 e 13.
