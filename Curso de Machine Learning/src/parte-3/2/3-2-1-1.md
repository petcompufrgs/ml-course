# Camada linear

Como foi apresentado nas seções anteriores, uma rede neural possui diversas camadas e cada uma
delas executa uma função sobre um dado. A primeira camada que iremos discutir é a camada mais
básica, a qual executa transformações lineares sobre os dados. A camada linear - do inglês _linear layer_ -
realiza o treino das camadas intermediárias da rede neural baseado no método de regressão
linear (Seção [Regressão linear](../../parte-2/2/2-2.md)).

A camada linear realiza uma soma ponderada dos dados de entrada, ou seja, realiza uma soma dos
resultados de funções afins da seguinte forma:

---

\\[
  \large{} y = \sum _i w _i x _i + b
\\]

---

Onde \\( w \\) são as conexões de cada neurônio da camada com os pesos (_weight_), \\( x \\) são os valores
dos neurônios conectados, \\( b \\) é o valor numérico _bias_ de cada camada (constante), \\( i \\) é o número de
conexões e \\( y \\) é o valor de saída do neurônio atual.

Os valores de \\( y \\) retornados irão percorrer toda a rede neural. Para isso, temos camadas de ativação as
quais irão adicionar complexidade e dimensionalidade para a rede neural. Essas camadas tem como
objetivo realizar transformações não-lineares dentro da rede. Com essas transformações, podemos
classificar dados mais complexos e que não se comportam de maneira linear. Essas camadas de ativação
podem ter diferentes formas e a mais comum delas é a chamada _dense layer_, cujos neurônios das
camadas subsequentes estão, de alguma forma, conectados com os neurônios da camada precedente.

A seguir, iremos discutir diferentes implementações da camada de ativação usando diferentes modelos
matemáticos
