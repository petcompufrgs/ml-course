# Função Custo (_Cost Function_)

Primeiramente, precisamos definir as variáveis que serão usadas para definir a função custo.

- \\( L \\) = número total de camadas (_layers_) na rede neural;

- \\( s _l \\) = número de unidades na camada \\( l \\) (sem contar a unidade bias);

- \\( K \\) = número de unidades/classes de saída (_output layer_).

Com isso podemos definir a função custo que será utilizada para calcular o custo de uma rede
neural. Utilizaremos como base a função custo da regressão logística vista na Seção
[Função Custo (Cost Function)](../../parte-2/9/2-9-1.md) a fim de
determinarmos o valor da saída da função \\( J(\Theta) \\).

A função custo para redes neurais tem o seguinte formato:

---

\\[
  J(\Theta)=- \frac{1}{m} \sum _{i=1} ^m \sum _{k=1} ^K \Big[ y _k ^{(i)} \log ((h _{\Theta}(x ^{(i)})) _k) +
    (1-y _k ^{(i)}) \log (1-(h _{\Theta}(x ^{(i)})) _k) \Big] + \frac{\lambda}{2m} \sum _{l=1} ^{L-1}
    \sum _{i=1} ^{s _l} \sum _{j=1} ^{s _{l+1}} (\Theta _{j,i} ^{(l)}) ^2
\\]

---

Podemos comparar esta equação com a equação da função custo da regressão logística. Assim,
percebe-se que adicionamos alguns somatórios. Nos dois primeiros somatórios, de \\( k=1 \\) até \\( K \\) e de
\\( i=1 \\) até \\( m \\), somamos os valores do retorno da função custo da regressão logística para cada nodo
da _output layer_. Nos três últimos somatórios, de \\( j=1 \\) até \\( s _{l+1} \\), de \\( i=1 \\) até
\\( s _l \\) e de \\( l=1 \\) até \\( L=1 \\), somamos os valores dos quadrados de todos os valores de
\\( \Theta \\) individuais em toda a rede neural.
