# Estrutura básica

Uma rede neural consiste em uma sequência de camadas nas quais os dados são aplicados a transformações
lineares e não lineares. Cada uma dessas camadas é composta por neurônios (_neurons_ ou _units_) e cada
um desses neurônios estão conectados com os próximos, presentes na camada seguinte.
Essas conexões são chamadas de pesos (_weights_) - um valor numérico. E, além disso, cada camada
possui um valor fixo numérico, chamado de _bias_. Assim, os dados passamos como entrada começam
na _input layer_, passando por transformações lineares e não lineares nas camadas internas até atingir
a _output layer_.

Com isso, o aprendizado de uma rede neural tem como objetivo otimizar a função custo (_loss function_) de
acordo com os parâmetros, geralmente através da regra da cadeia ou através do método
do gradiente descendente.

Nas próximas subseções iremos discutir os conceitos fundamentais para a estruturação básica de uma
rede neural, apresentando os principais modelos e arquiteturas utilizados.
